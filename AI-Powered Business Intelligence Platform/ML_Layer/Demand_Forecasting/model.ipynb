{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date category      region  quantity\n",
      "0  2023-01-01    dairy    Barishal     182.0\n",
      "1  2023-01-01    dairy  Chattogram     198.0\n",
      "2  2023-01-01    dairy       Dhaka     146.0\n",
      "3  2023-01-01    dairy      Khulna     187.0\n",
      "4  2023-01-01    dairy  Mymensingh     225.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"warehouse_sales_export.csv\", )\n",
    "df.rename(columns={\"ds\": \"date\", \"y\": \"quantity\"}, inplace=True)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e56bd3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78912 entries, 0 to 78911\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   ds        78912 non-null  object \n",
      " 1   category  78912 non-null  object \n",
      " 2   region    78912 non-null  object \n",
      " 3   y         78912 non-null  float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 2.4+ MB\n",
      "None\n",
      "Dataset describe \n",
      "                  y\n",
      "count  78912.000000\n",
      "mean     209.007984\n",
      "std       42.942520\n",
      "min       32.000000\n",
      "25%      179.000000\n",
      "50%      207.000000\n",
      "75%      237.000000\n",
      "max      411.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset info \")\n",
    "print(df.info())\n",
    "print(\"Dataset describe \")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "495ceff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ds          0\n",
       "category    0\n",
       "region      0\n",
       "y           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values and handle them if necessary:\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ca8ba",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c68fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "315d26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['order_date'] = pd.to_datetime(df['ds'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bdb528",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "978533cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>order_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_30</th>\n",
       "      <th>rolling_7</th>\n",
       "      <th>...</th>\n",
       "      <th>region_Sylhet</th>\n",
       "      <th>category_dairy</th>\n",
       "      <th>category_fish</th>\n",
       "      <th>category_fruits</th>\n",
       "      <th>category_meat</th>\n",
       "      <th>category_oil</th>\n",
       "      <th>category_rice</th>\n",
       "      <th>category_snacks</th>\n",
       "      <th>category_spices</th>\n",
       "      <th>category_vegetables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>204.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>173.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>214.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>179.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>204.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>201.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>244.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>179.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>196.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>139.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>244.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>197.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>158.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>139.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78907</th>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>233.0</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>174.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>210.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78908</th>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>212.0</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>233.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>213.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78909</th>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>212.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78910</th>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>209.0</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>201.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78911</th>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>236.0</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>209.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78882 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ds      y order_date  day_of_week  month  quarter  lag_1  \\\n",
       "30     2023-01-01  204.0 2023-01-01            6      1        1  173.0   \n",
       "31     2023-01-01  179.0 2023-01-01            6      1        1  204.0   \n",
       "32     2023-01-01  244.0 2023-01-01            6      1        1  179.0   \n",
       "33     2023-01-01  139.0 2023-01-01            6      1        1  244.0   \n",
       "34     2023-01-01  158.0 2023-01-01            6      1        1  139.0   \n",
       "...           ...    ...        ...          ...    ...      ...    ...   \n",
       "78907  2025-12-31  233.0 2025-12-31            2     12        4  174.0   \n",
       "78908  2025-12-31  212.0 2025-12-31            2     12        4  233.0   \n",
       "78909  2025-12-31  201.0 2025-12-31            2     12        4  212.0   \n",
       "78910  2025-12-31  209.0 2025-12-31            2     12        4  201.0   \n",
       "78911  2025-12-31  236.0 2025-12-31            2     12        4  209.0   \n",
       "\n",
       "       lag_7  lag_30   rolling_7  ...  region_Sylhet  category_dairy  \\\n",
       "30     195.0   182.0  214.142857  ...          False           False   \n",
       "31     266.0   198.0  201.714286  ...           True           False   \n",
       "32     278.0   146.0  196.857143  ...          False           False   \n",
       "33     135.0   187.0  197.428571  ...          False           False   \n",
       "34     217.0   225.0  189.000000  ...          False           False   \n",
       "...      ...     ...         ...  ...            ...             ...   \n",
       "78907  304.0   181.0  210.857143  ...          False           False   \n",
       "78908  196.0   220.0  213.142857  ...          False           False   \n",
       "78909  314.0   157.0  197.000000  ...          False           False   \n",
       "78910  139.0   217.0  207.000000  ...          False           False   \n",
       "78911  166.0   232.0  217.000000  ...           True           False   \n",
       "\n",
       "       category_fish  category_fruits  category_meat  category_oil  \\\n",
       "30             False            False           True         False   \n",
       "31             False            False           True         False   \n",
       "32             False            False          False          True   \n",
       "33             False            False          False          True   \n",
       "34             False            False          False          True   \n",
       "...              ...              ...            ...           ...   \n",
       "78907          False            False          False         False   \n",
       "78908          False            False          False         False   \n",
       "78909          False            False          False         False   \n",
       "78910          False            False          False         False   \n",
       "78911          False            False          False         False   \n",
       "\n",
       "       category_rice  category_snacks  category_spices  category_vegetables  \n",
       "30             False            False            False                False  \n",
       "31             False            False            False                False  \n",
       "32             False            False            False                False  \n",
       "33             False            False            False                False  \n",
       "34             False            False            False                False  \n",
       "...              ...              ...              ...                  ...  \n",
       "78907          False            False            False                 True  \n",
       "78908          False            False            False                 True  \n",
       "78909          False            False            False                 True  \n",
       "78910          False            False            False                 True  \n",
       "78911          False            False            False                 True  \n",
       "\n",
       "[78882 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display_functions import display\n",
    "# Extract time-based features\n",
    "df['day_of_week'] = df['order_date'].dt.dayofweek\n",
    "df['month'] = df['order_date'].dt.month\n",
    "df['quarter'] = df['order_date'].dt.quarter\n",
    "\n",
    "# Lag features\n",
    "df['lag_1'] = df['y'].shift(1)\n",
    "df['lag_7'] = df['y'].shift(7)\n",
    "df['lag_30'] = df['y'].shift(30)\n",
    "\n",
    "# Rolling features\n",
    "df['rolling_7'] = df['y'].rolling(7).mean()\n",
    "df['rolling_30'] = df['y'].rolling(30).mean()\n",
    "\n",
    "# One-hot encode categorical features\n",
    "df = pd.get_dummies(df, columns=['region', 'category'])\n",
    "df.dropna(inplace=True)  # remove rows with NaN after lag/rolling\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa3d048",
   "metadata": {},
   "source": [
    "Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3417e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df) * 0.8)\n",
    "train = df.iloc[:train_size]\n",
    "test = df.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af459038",
   "metadata": {},
   "source": [
    "Model Selection\n",
    "\n",
    "We will compare 3 models for demand forecast:\n",
    "\n",
    "* Prophet (Time-series model)\n",
    "\n",
    "* XGBoost / LightGBM (ML regression)\n",
    "\n",
    "* Simple baseline (like last week average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de802e",
   "metadata": {},
   "source": [
    "## Prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a456fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fe6897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:44:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "03:44:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "prophet_df = df.groupby('order_date')['y'].sum().reset_index()\n",
    "prophet_df.rename(columns={'order_date': 'ds',}, inplace=True)\n",
    "\n",
    "model_prophet = Prophet(daily_seasonality=True, yearly_seasonality=True)\n",
    "model_prophet.fit(prophet_df.iloc[:train_size])\n",
    "\n",
    "future = model_prophet.make_future_dataframe(periods=len(test))\n",
    "forecast = model_prophet.predict(future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b315c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prophet MAE: 14640.171502582376\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae_prophet = mean_absolute_error(forecast['yhat'][-len(test):], test['y'])\n",
    "print(\"Prophet MAE:\", mae_prophet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3dd4de",
   "metadata": {},
   "source": [
    "## XGBoost / LightGBM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb9009d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ds', 'y', 'order_date', 'day_of_week', 'month', 'quarter', 'lag_1',\n",
       "       'lag_7', 'lag_30', 'rolling_7', 'rolling_30', 'region_Barishal',\n",
       "       'region_Chattogram', 'region_Dhaka', 'region_Khulna',\n",
       "       'region_Mymensingh', 'region_Rajshahi', 'region_Rangpur',\n",
       "       'region_Sylhet', 'category_dairy', 'category_fish', 'category_fruits',\n",
       "       'category_meat', 'category_oil', 'category_rice', 'category_snacks',\n",
       "       'category_spices', 'category_vegetables'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "970f21b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MAE: 31.586419617577395\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 1️⃣ Define features\n",
    "features = [c for c in df.columns if c not in ['order_date', 'y']]\n",
    "\n",
    "# 2️⃣ Convert datetime columns to numeric features\n",
    "for df_split in [train, test]:\n",
    "    if 'order_date' in df_split.columns:\n",
    "        df_split['order_date'] = pd.to_datetime(df_split['order_date'])\n",
    "        df_split['day'] = df_split['order_date'].dt.day\n",
    "        df_split['month'] = df_split['order_date'].dt.month\n",
    "        df_split['year'] = df_split['order_date'].dt.year\n",
    "        df_split['day_of_week'] = df_split['order_date'].dt.dayofweek\n",
    "        df_split.drop('order_date', axis=1, inplace=True)\n",
    "\n",
    "# 3️⃣ Make sure all features are numeric\n",
    "X_train = train[features].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "y_train = train['y']\n",
    "X_test = test[features].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "y_test = test['y']\n",
    "\n",
    "# 4️⃣ Train XGBoost\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.05)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 5️⃣ Predict & Evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "print(\"XGBoost MAE:\", mae_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee7cfb3",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "Simple last week average forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1d53893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAE: 48.533815047220635\n"
     ]
    }
   ],
   "source": [
    "y_pred_baseline = test['lag_7'].values\n",
    "mae_baseline = mean_absolute_error(y_test, y_pred_baseline)\n",
    "print(\"Baseline MAE:\", mae_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6d040d",
   "metadata": {},
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec7b237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Comparison:\n",
      "Prophet: 14640.17\n",
      "XGBoost: 31.59\n",
      "Baseline: 48.53\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE Comparison:\")\n",
    "print(f\"Prophet: {mae_prophet:.2f}\")\n",
    "print(f\"XGBoost: {mae_xgb:.2f}\")\n",
    "print(f\"Baseline: {mae_baseline:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73c978b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['ds', 'day_of_week', 'month', 'quarter', 'lag_1', 'lag_7', 'lag_30', 'rolling_7', 'rolling_30', 'region_Barishal', 'region_Chattogram', 'region_Dhaka', 'region_Khulna', 'region_Mymensingh', 'region_Rajshahi', 'region_Rangpur', 'region_Sylhet', 'category_dairy', 'category_fish', 'category_fruits', 'category_meat', 'category_oil', 'category_rice', 'category_snacks', 'category_spices', 'category_vegetables'] ['day_of_week', 'month', 'quarter', 'lag_1', 'lag_7', 'lag_30', 'rolling_7', 'rolling_30', 'region_Barishal', 'region_Chattogram', 'region_Dhaka', 'region_Khulna', 'region_Mymensingh', 'region_Rajshahi', 'region_Rangpur', 'region_Sylhet', 'category_dairy', 'category_fish', 'category_fruits', 'category_meat', 'category_oil', 'category_rice', 'category_snacks', 'category_spices', 'category_vegetables']\nexpected ds in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m     future_features = future_features.apply(pd.to_numeric, errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m).fillna(\u001b[32m0\u001b[39m)\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     forecast_final = \u001b[43mfinal_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mae_prophet < mae_baseline:\n\u001b[32m     29\u001b[39m     final_model = model_prophet\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\Data Analysis Portfolio Project\\env\\Lib\\site-packages\\xgboost\\core.py:751\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    750\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\Data Analysis Portfolio Project\\env\\Lib\\site-packages\\xgboost\\sklearn.py:1446\u001b[39m, in \u001b[36mXGBModel.predict\u001b[39m\u001b[34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[39m\n\u001b[32m   1444\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._can_use_inplace_predict():\n\u001b[32m   1445\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1446\u001b[39m         predts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1447\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1448\u001b[39m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1449\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmargin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1450\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1451\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1452\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1453\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1454\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[32m   1455\u001b[39m             cp = import_cupy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\Data Analysis Portfolio Project\\env\\Lib\\site-packages\\xgboost\\core.py:751\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    750\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\Data Analysis Portfolio Project\\env\\Lib\\site-packages\\xgboost\\core.py:2854\u001b[39m, in \u001b[36mBooster.inplace_predict\u001b[39m\u001b[34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[39m\n\u001b[32m   2852\u001b[39m     data, fns, _ = _transform_pandas_df(data, enable_categorical)\n\u001b[32m   2853\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[32m-> \u001b[39m\u001b[32m2854\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data) \u001b[38;5;129;01mor\u001b[39;00m _is_tuple(data):\n\u001b[32m   2856\u001b[39m     data = np.array(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\Data Analysis Portfolio Project\\env\\Lib\\site-packages\\xgboost\\core.py:3429\u001b[39m, in \u001b[36mBooster._validate_features\u001b[39m\u001b[34m(self, feature_names)\u001b[39m\n\u001b[32m   3423\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m my_missing:\n\u001b[32m   3424\u001b[39m     msg += (\n\u001b[32m   3425\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mtraining data did not have the following fields: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3426\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m my_missing)\n\u001b[32m   3427\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m3429\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg.format(\u001b[38;5;28mself\u001b[39m.feature_names, feature_names))\n",
      "\u001b[31mValueError\u001b[39m: feature_names mismatch: ['ds', 'day_of_week', 'month', 'quarter', 'lag_1', 'lag_7', 'lag_30', 'rolling_7', 'rolling_30', 'region_Barishal', 'region_Chattogram', 'region_Dhaka', 'region_Khulna', 'region_Mymensingh', 'region_Rajshahi', 'region_Rangpur', 'region_Sylhet', 'category_dairy', 'category_fish', 'category_fruits', 'category_meat', 'category_oil', 'category_rice', 'category_snacks', 'category_spices', 'category_vegetables'] ['day_of_week', 'month', 'quarter', 'lag_1', 'lag_7', 'lag_30', 'rolling_7', 'rolling_30', 'region_Barishal', 'region_Chattogram', 'region_Dhaka', 'region_Khulna', 'region_Mymensingh', 'region_Rajshahi', 'region_Rangpur', 'region_Sylhet', 'category_dairy', 'category_fish', 'category_fruits', 'category_meat', 'category_oil', 'category_rice', 'category_snacks', 'category_spices', 'category_vegetables']\nexpected ds in input data"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if mae_xgb < mae_prophet and mae_xgb < mae_baseline:\n",
    "    final_model = xgb_model\n",
    "    \n",
    "    # Prepare next 30 rows for prediction\n",
    "    future_features = df[features].tail(30).copy()\n",
    "\n",
    "    # Convert datetime if present\n",
    "    if 'order_date' in future_features.columns:\n",
    "        future_features['order_date'] = pd.to_datetime(future_features['order_date'])\n",
    "        future_features['day'] = future_features['order_date'].dt.day\n",
    "        future_features['month'] = future_features['order_date'].dt.month\n",
    "        future_features['year'] = future_features['order_date'].dt.year\n",
    "        future_features['day_of_week'] = future_features['order_date'].dt.dayofweek\n",
    "        future_features = future_features.drop('order_date', axis=1)\n",
    "    \n",
    "    # Drop any leftover object columns (like 'ds' from Prophet)\n",
    "    object_cols = future_features.select_dtypes(include='object').columns\n",
    "    future_features = future_features.drop(columns=object_cols)\n",
    "    \n",
    "    # Ensure numeric\n",
    "    future_features = future_features.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    \n",
    "    # Predict\n",
    "    forecast_final = final_model.predict(future_features)\n",
    "    \n",
    "elif mae_prophet < mae_baseline:\n",
    "    final_model = model_prophet\n",
    "    future = final_model.make_future_dataframe(periods=30)\n",
    "    forecast_final = final_model.predict(future)['yhat'][-30:]\n",
    "else:\n",
    "    forecast_final = df['lag_7'].tail(30).values  # baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663bb3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40bce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba567a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22477b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2023-01-15 -> 2025-12-01 rows: 75744\n",
      "Val:   2025-12-02 -> 2025-12-31 rows: 2160\n",
      "\n",
      "Model Evaluation (lower MAE is better):\n",
      "          model    val_MAE\n",
      "0    ElasticNet  34.566351\n",
      "1         Lasso  34.566803\n",
      "2         Ridge  34.566905\n",
      "3        HistGB  34.640254\n",
      "4  RandomForest  35.098464\n",
      "\n",
      "Best model selected: ElasticNet\n",
      "Best model retrained on full dataset.\n",
      "\n",
      "Forecast sample:\n",
      "        date category    region  predicted_quantity\n",
      "0 2026-01-01    dairy  Barishal          207.383576\n",
      "1 2026-01-02    dairy  Barishal          208.191854\n",
      "2 2026-01-03    dairy  Barishal          207.400219\n",
      "3 2026-01-04    dairy  Barishal          207.241983\n",
      "4 2026-01-05    dairy  Barishal          207.699367\n",
      "5 2026-01-06    dairy  Barishal          207.665238\n",
      "6 2026-01-07    dairy  Barishal          208.327115\n",
      "7 2026-01-08    dairy  Barishal          207.913731\n",
      "8 2026-01-09    dairy  Barishal          208.357284\n",
      "9 2026-01-10    dairy  Barishal          207.248266\n",
      "\n",
      "Saved: forecast_15_days.csv\n"
     ]
    }
   ],
   "source": [
    "# Demand Forecasting (Category × Region) with 5 models\n",
    "# - Builds lag/rolling/calendar features\n",
    "# - Time-based split (last 30 days validation)\n",
    "# - Trains 5 models, evaluates MAE, picks best\n",
    "# - Forecasts next 15 days (recursive)\n",
    "#\n",
    "# Required df columns: date, category, region, quantity\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Prepare data\n",
    "# -----------------------------\n",
    "df = df.copy()\n",
    "\n",
    "# handle prophet-like columns if present\n",
    "if \"ds\" in df.columns:\n",
    "    df = df.rename(columns={\"ds\": \"date\"})\n",
    "if \"y\" in df.columns:\n",
    "    df = df.rename(columns={\"y\": \"quantity\"})\n",
    "\n",
    "required = {\"date\", \"category\", \"region\", \"quantity\"}\n",
    "missing = required - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns: {missing}. Required: {required}\")\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"quantity\"] = pd.to_numeric(df[\"quantity\"], errors=\"coerce\").fillna(0.0)\n",
    "df = df.sort_values([\"category\", \"region\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Feature engineering\n",
    "# -----------------------------\n",
    "def make_features(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = data.sort_values([\"category\", \"region\", \"date\"]).copy()\n",
    "\n",
    "    # calendar\n",
    "    d[\"dow\"] = d[\"date\"].dt.dayofweek\n",
    "    d[\"month\"] = d[\"date\"].dt.month\n",
    "    d[\"is_weekend\"] = (d[\"dow\"] >= 5).astype(int)\n",
    "\n",
    "    # lag + rolling per category-region\n",
    "    g = d.groupby([\"category\", \"region\"], sort=False)\n",
    "\n",
    "    d[\"lag_1\"] = g[\"quantity\"].shift(1)\n",
    "    d[\"lag_7\"] = g[\"quantity\"].shift(7)\n",
    "    d[\"lag_14\"] = g[\"quantity\"].shift(14)\n",
    "    d[\"rollmean_7\"] = g[\"quantity\"].shift(1).rolling(7).mean()\n",
    "\n",
    "    return d\n",
    "\n",
    "feat = make_features(df)\n",
    "\n",
    "# remove early rows (need history)\n",
    "feat = feat.dropna(subset=[\"lag_14\", \"rollmean_7\"]).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Time-based split (last 30 days)\n",
    "# -----------------------------\n",
    "VAL_DAYS = 30\n",
    "max_date = feat[\"date\"].max()\n",
    "val_start = max_date - pd.Timedelta(days=VAL_DAYS - 1)\n",
    "\n",
    "train_df = feat[feat[\"date\"] < val_start].copy()\n",
    "val_df = feat[feat[\"date\"] >= val_start].copy()\n",
    "\n",
    "print(\"Train:\", train_df[\"date\"].min().date(), \"->\", train_df[\"date\"].max().date(), \"rows:\", len(train_df))\n",
    "print(\"Val:  \", val_df[\"date\"].min().date(), \"->\", val_df[\"date\"].max().date(), \"rows:\", len(val_df))\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Prepare X/y\n",
    "# -----------------------------\n",
    "cat_cols = [\"category\", \"region\"]\n",
    "num_cols = [\"dow\", \"month\", \"is_weekend\", \"lag_1\", \"lag_7\", \"lag_14\", \"rollmean_7\"]\n",
    "\n",
    "X_train = train_df[cat_cols + num_cols]\n",
    "y_train = train_df[\"quantity\"].astype(float)\n",
    "\n",
    "X_val = val_df[cat_cols + num_cols]\n",
    "y_val = val_df[\"quantity\"].astype(float)\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))]), num_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Define 5 models\n",
    "# -----------------------------\n",
    "models = {\n",
    "    \"Ridge\": Ridge(alpha=1.0, random_state=42),\n",
    "    \"Lasso\": Lasso(alpha=0.001, random_state=42, max_iter=5000),\n",
    "    \"ElasticNet\": ElasticNet(alpha=0.001, l1_ratio=0.5, random_state=42, max_iter=5000),\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        n_estimators=400, random_state=42, n_jobs=-1, min_samples_leaf=2\n",
    "    ),\n",
    "    \"HistGB\": HistGradientBoostingRegressor(\n",
    "        random_state=42, max_depth=8, learning_rate=0.07, max_iter=400\n",
    "    ),\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Train + Evaluate\n",
    "# -----------------------------\n",
    "results = []\n",
    "fitted = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([(\"prep\", preprocess), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    pred = pipe.predict(X_val)\n",
    "    pred = np.clip(pred, 0, None)  # demand can't be negative\n",
    "\n",
    "    mae = mean_absolute_error(y_val, pred)\n",
    "    results.append({\"model\": name, \"val_MAE\": mae})\n",
    "    fitted[name] = pipe\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_MAE\").reset_index(drop=True)\n",
    "print(\"\\nModel Evaluation (lower MAE is better):\")\n",
    "print(results_df)\n",
    "\n",
    "best_model_name = results_df.loc[0, \"model\"]\n",
    "best_model = fitted[best_model_name]\n",
    "print(\"\\nBest model selected:\", best_model_name)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Retrain best model on ALL data\n",
    "# -----------------------------\n",
    "X_all = feat[cat_cols + num_cols]\n",
    "y_all = feat[\"quantity\"].astype(float)\n",
    "\n",
    "best_model.fit(X_all, y_all)\n",
    "print(\"Best model retrained on full dataset.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Forecast next 15 days (recursive)\n",
    "# -----------------------------\n",
    "HORIZON = 15\n",
    "\n",
    "def forecast_next_days(df_original: pd.DataFrame, trained_model, horizon: int = 15) -> pd.DataFrame:\n",
    "    hist = df_original.copy()\n",
    "    hist[\"date\"] = pd.to_datetime(hist[\"date\"])\n",
    "    hist = hist.sort_values([\"category\", \"region\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "    last_date = hist[\"date\"].max()\n",
    "    future_dates = pd.date_range(last_date + pd.Timedelta(days=1), periods=horizon, freq=\"D\")\n",
    "\n",
    "    forecasts = []\n",
    "\n",
    "    for (cat, reg), g in hist.groupby([\"category\", \"region\"], sort=False):\n",
    "        g = g.sort_values(\"date\").copy()\n",
    "\n",
    "        for d in future_dates:\n",
    "            # add placeholder row\n",
    "            g = pd.concat([g, pd.DataFrame([{\n",
    "                \"date\": d, \"category\": cat, \"region\": reg, \"quantity\": np.nan\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "            # build features for this group (so lags are correct)\n",
    "            gg = make_features(g)\n",
    "            row = gg.iloc[-1]\n",
    "\n",
    "            # if not enough history\n",
    "            if pd.isna(row[\"lag_14\"]) or pd.isna(row[\"rollmean_7\"]):\n",
    "                yhat = 0.0\n",
    "            else:\n",
    "                X_row = pd.DataFrame([{\n",
    "                    \"category\": cat,\n",
    "                    \"region\": reg,\n",
    "                    \"dow\": int(row[\"dow\"]),\n",
    "                    \"month\": int(row[\"month\"]),\n",
    "                    \"is_weekend\": int(row[\"is_weekend\"]),\n",
    "                    \"lag_1\": float(row[\"lag_1\"]),\n",
    "                    \"lag_7\": float(row[\"lag_7\"]),\n",
    "                    \"lag_14\": float(row[\"lag_14\"]),\n",
    "                    \"rollmean_7\": float(row[\"rollmean_7\"]),\n",
    "                }])\n",
    "\n",
    "                yhat = float(trained_model.predict(X_row)[0])\n",
    "                yhat = max(0.0, yhat)\n",
    "\n",
    "            # write prediction back for next day's lag features\n",
    "            g.loc[g.index[-1], \"quantity\"] = yhat\n",
    "\n",
    "            forecasts.append({\n",
    "                \"date\": d,\n",
    "                \"category\": cat,\n",
    "                \"region\": reg,\n",
    "                \"predicted_quantity\": yhat\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(forecasts)\n",
    "\n",
    "forecast_15 = forecast_next_days(df, best_model, horizon=HORIZON)\n",
    "\n",
    "print(\"\\nForecast sample:\")\n",
    "print(forecast_15.head(10))\n",
    "\n",
    "forecast_15.to_csv(\"forecast_15_days.csv\", index=False)\n",
    "print(\"\\nSaved: forecast_15_days.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c2180c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model leaderboard:\n",
      "          model    val_MAE\n",
      "0    ElasticNet  34.566351\n",
      "1         Lasso  34.566803\n",
      "2         Ridge  34.566905\n",
      "3        HistGB  34.640254\n",
      "4  RandomForest  35.098464\n",
      "Best model: ElasticNet\n",
      "Saved model -> saved_model\\best_model.pkl\n",
      "Saved meta  -> saved_model\\meta.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "\n",
    "# =============================\n",
    "# CONFIG\n",
    "# =============================\n",
    "VAL_DAYS = 30\n",
    "MODEL_DIR = \"saved_model\"\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"best_model.pkl\")\n",
    "META_PATH = os.path.join(MODEL_DIR, \"meta.json\")\n",
    "\n",
    "\n",
    "# =============================\n",
    "# FEATURE ENGINEERING\n",
    "# =============================\n",
    "def make_features(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = data.sort_values([\"category\", \"region\", \"date\"]).copy()\n",
    "\n",
    "    # calendar\n",
    "    d[\"dow\"] = d[\"date\"].dt.dayofweek\n",
    "    d[\"month\"] = d[\"date\"].dt.month\n",
    "    d[\"is_weekend\"] = (d[\"dow\"] >= 5).astype(int)\n",
    "\n",
    "    # lags/rolling by group\n",
    "    g = d.groupby([\"category\", \"region\"], sort=False)\n",
    "\n",
    "    d[\"lag_1\"] = g[\"quantity\"].shift(1)\n",
    "    d[\"lag_7\"] = g[\"quantity\"].shift(7)\n",
    "    d[\"lag_14\"] = g[\"quantity\"].shift(14)\n",
    "    d[\"rollmean_7\"] = g[\"quantity\"].shift(1).rolling(7).mean()\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "def train_and_save(df: pd.DataFrame):\n",
    "    # basic cleanup\n",
    "    df = df.copy()\n",
    "    if \"ds\" in df.columns:\n",
    "        df = df.rename(columns={\"ds\": \"date\"})\n",
    "    if \"y\" in df.columns:\n",
    "        df = df.rename(columns={\"y\": \"quantity\"})\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"quantity\"] = pd.to_numeric(df[\"quantity\"], errors=\"coerce\").fillna(0.0)\n",
    "    df = df.sort_values([\"category\", \"region\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "    feat = make_features(df)\n",
    "    feat = feat.dropna(subset=[\"lag_14\", \"rollmean_7\"]).reset_index(drop=True)\n",
    "\n",
    "    # time split\n",
    "    max_date = feat[\"date\"].max()\n",
    "    val_start = max_date - pd.Timedelta(days=VAL_DAYS - 1)\n",
    "\n",
    "    train_df = feat[feat[\"date\"] < val_start].copy()\n",
    "    val_df   = feat[feat[\"date\"] >= val_start].copy()\n",
    "\n",
    "    cat_cols = [\"category\", \"region\"]\n",
    "    num_cols = [\"dow\", \"month\", \"is_weekend\", \"lag_1\", \"lag_7\", \"lag_14\", \"rollmean_7\"]\n",
    "\n",
    "    X_train = train_df[cat_cols + num_cols]\n",
    "    y_train = train_df[\"quantity\"].astype(float)\n",
    "\n",
    "    X_val = val_df[cat_cols + num_cols]\n",
    "    y_val = val_df[\"quantity\"].astype(float)\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "            (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))]), num_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 5 models\n",
    "    models = {\n",
    "        \"Ridge\": Ridge(alpha=1.0, random_state=42),\n",
    "        \"Lasso\": Lasso(alpha=0.001, random_state=42, max_iter=5000),\n",
    "        \"ElasticNet\": ElasticNet(alpha=0.001, l1_ratio=0.5, random_state=42, max_iter=5000),\n",
    "        \"RandomForest\": RandomForestRegressor(\n",
    "            n_estimators=400, random_state=42, n_jobs=-1, min_samples_leaf=2\n",
    "        ),\n",
    "        \"HistGB\": HistGradientBoostingRegressor(\n",
    "            random_state=42, max_depth=8, learning_rate=0.07, max_iter=400\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # train + evaluate\n",
    "    results = []\n",
    "    fitted = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        pipe = Pipeline([(\"prep\", preprocess), (\"model\", model)])\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "        pred = np.clip(pipe.predict(X_val), 0, None)\n",
    "        mae = mean_absolute_error(y_val, pred)\n",
    "\n",
    "        results.append({\"model\": name, \"val_MAE\": float(mae)})\n",
    "        fitted[name] = pipe\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(\"val_MAE\").reset_index(drop=True)\n",
    "    best_name = results_df.loc[0, \"model\"]\n",
    "    best_pipe = fitted[best_name]\n",
    "\n",
    "    print(\"Model leaderboard:\")\n",
    "    print(results_df)\n",
    "    print(\"Best model:\", best_name)\n",
    "\n",
    "    # retrain best on all data\n",
    "    X_all = feat[cat_cols + num_cols]\n",
    "    y_all = feat[\"quantity\"].astype(float)\n",
    "    best_pipe.fit(X_all, y_all)\n",
    "\n",
    "    # save\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    joblib.dump(best_pipe, MODEL_PATH)\n",
    "\n",
    "    meta = {\n",
    "        \"best_model\": best_name,\n",
    "        \"val_days\": VAL_DAYS,\n",
    "        \"feature_columns\": {\"cat\": cat_cols, \"num\": num_cols},\n",
    "        \"leaderboard\": results_df.to_dict(orient=\"records\"),\n",
    "        \"trained_until\": str(df[\"date\"].max().date()),\n",
    "    }\n",
    "    with open(META_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    print(f\"Saved model -> {MODEL_PATH}\")\n",
    "    print(f\"Saved meta  -> {META_PATH}\")\n",
    "\n",
    "\n",
    "# =============================\n",
    "# RUN (example)\n",
    "# =============================\n",
    "if __name__ == \"__main__\":\n",
    "  \n",
    "    train_and_save(df)  # assumes df already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f9abb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
